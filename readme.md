# Introduction
This repository contains Terraform code which:
- Creates AKS
- Generates a Dockerfile - Which can be used to run a container with prepared environment to interact with created AKS. From that container we can:
    - Deploy MLflow Tracking Server on AKS
    - Run MLflow project on AKS

For deploying MLflow Tracking Server and running MLflow project we will be using Helm charts from this repository, in the docker > helm_charts folder:
- mlflow_project - Running a project
- mlflow_setup - Deploying Tracking Server and preparing other resources needed to run the project

Both Helm charts will be copied to the container for interacting with AKS.

Further in this document we have the following main sections:
- Important notes before you use this repo - Read this first before start working with code from this repo
- Repository guide - How to use this code
- Prerequisites - What we need to do before we start using code from this repo
- Deploy MLflow resources on AKS - details - Deploying resources needed for the MLflow Tracking Server and project using Helm chart
- MLflow project - How do we prepare a MLflow project for training and evaluating model
- Docker container for interacting with AKS - More details about the Docker image created using the Dockerfile generated by Terraform
- Creating Azure resources with Terraform - What Azure resources we create using Terraform and how
- 'AKS resources deployment - details' - More details about how do we deploy resources on AKS





# Important notes before you use this repo
Here are important informations you need to know before you start working with this repo.

## Why to use Docker?
We are using here Docker to prepare environment to interact with AKS but it is not necessary to use it.

Instead of running a Docker container on our machine, we can prepare environment for interacting with AKS on our host machine itself.

If we have a Linux or MacOS, then we can take bash scripts from this Dockerfile and execute them on our machine.

## Sensitive data
Some files generated by Terraform will contain some sensitive data - credentials to a Service Principal used for authentication when interacting with AKS and ACR. Those files should be included in the .gitignore:
- Dockerfile
- values.yaml





# Repository guide
Here is described how to use code from this repository.

## Satisfying prerequisites
Before we start using this code we need to satisfy prerequisites described in the 'Prerequisites' section further in this document.

## Creating Azure resources and generating a Dockerfile
We need to create a few resources in Azure:
- AKS
- Storage Account
- ACR

Also we need to generate a few files which content depends on the created Azure resources:
- Dockerfile:
    - Used to run a container with prepared environment to interact with AKS
    - Saved in the docker folder
- values.yaml x2:
    - Two values.yaml files used in Helm charts:
    - Saved in the mlflow_project and mlflow_setup folders in the docker > helm_charts folder.

In order to create all those resources and generate files we need to run the following commands in the terraform folder:
>- terraform init # only when running Terraform for the first time in this repository
>- terraform plan -out main.tfplan
>- terraform apply main.tfplan

## Run a Docker container for interacting with AKS
Now we need to build a Docker image and run a container using the Dockerfile generated by Terraform. We can do that using the following commands (run them in the 'docker' folder):
>docker build -t aks .          # Build the image
>docker run -it aks /bin/bash   # Run container and give us access to a bash session running in it.

This container will be used to interact with AKS. From inside of it we will perform actions described in the next steps in this guide:
- Deploy MLflow Tracking Server on AKS
- Run MLflow project

## Deploy MLflow resources on AKS
Now from inside of the container we can deploy the MLflow Tracking Server and all the resources needed for running the MLflow project using Helm.

We do this by running the following commands in the /root/k8s/helm_charts > mlflow_setup directory:
>helm dependency update                             # <- Install dependency chart, i.e. MySQL (backend store)
>helm install mlflow . -n mlflow --create-namespace # <- Install the chart   

More information about what resources we are deploying here can be found further in this document in the 'MLflow setup Helm chart' section.

## Accessing MLflow Tracking Server website
We need to get a public IP of the Kubernetes Service which our Tracking Server Deployment is using:
>kubectl -n mlflow get svc mlflow-service

There will be written 'EXTERNAL-IP' which is our needed public IP.

We can access MLflow Tracking Server website using this URL:
>Public-IP:5000

## Run MLflow project
Now we can run the MLflow project using Helm. We need to run the below command in the /root/k8s/helm_charts > mlflow_project directory:
>helm install run1 . -n mlflow

This will create a Job and a Pod called 'run1-mlflow-project-job-xxx'.

## Destroying Azure resources
Once we are done, then in order to destroy all the created resources in Azure we need to run the following commands:
>- terraform plan -destroy -out main.destroy.tfplan
>- terraform apply main.destroy.tfplan








# Prerequisites
## Terraform variables
Before using this code we need to create terraform.tfvars file which look like terraform-draft.tfvars file in the same location. It is described there what values to provide. We are assigning there values to variables from the variables.tf file located in the same folder. In the variables.tf we can also find descriptions of those variables. We need to assign values only for those variables which doesn't have assigned the default value.

## Terraform configuration
We need to configure properly Terraform on our computer so it can create resources in our Azure subscription, it is described here: [developer.hashicorp.com](https://developer.hashicorp.com/terraform/tutorials/azure-get-started/azure-build).

## Azure subscription
We need to have a subscription on the Azure platform portal.azure.com.





# MLflow setup Helm chart
We use the Helm chart from the docker > helm_charts > mlflow_setup folder to deploy all the resources needed to run MLflow projects. There are 3 subfolders in the templates folder for deploying different resources:
- common - Common resources for both, deploying the Tracking Server and running MLflow project:
    - ACR Secret 
        - Created by the acr-secret.yaml template.
        - Contains value for authentication when pulling images from ACR.
        - Used by the Tracking Server deployment and in the Service Account used in the Job running MLflow project.
- mlflow_project - Resources needed specifically for running MLflow project (not related to the Tracking Server):
    - Volume claim
        - Created by the pvc.yaml template.
        - Used in the Job which runs MLflow project. It is linked to File share in Azure Storage Account and it provides project files to run.
    - Secret 
        - Created by the sa-secret.yaml template.
        - It is used by the Volume to authenticate when connecting to Storage Account.
    - Service Account 
        - Created by the service-account.yaml template.
        - Used in the Job which runs MLflow project. It enables reading a secret described in the next point.
    - Role binding 
        - Created by the service-account-role-binding.yaml template
        - Assing proper permissions to the Service Account allowing for reading secrets.
- tracking_server - Resources used for deploying Tracking Server:
    - Volume Claim 
        - Created by the mysql-pvc.yaml template
        - Which will be used by MySQL which will act as a backend store. It will store data in Azure Disk.
    - Tracking Server Secret 
        - Created by the secret.yaml template
        - With values for connecting to MySQL (backend store) and Azure Storage Account (artifact store)
    - MLflow Tracking Server deployment with a Service
        - Created by the deployment.yaml and service.yaml templates
        - Services is used to assign DNS name to the Tracking Server Pod

In the chart dependencies we have:
    - MySQL - Which will act as a backend store.

Everything will be running in the namespace we define. We install this chart by running the following commands in the /root/k8s/helm_charts > mlflow_setup directory:
>helm dependency update                             # <- Install dependency chart, i.e. MySQL (backend store)
>helm install mlflow . -n mlflow --create-namespace # <- Install the chart 

For deploying this chart we need:
- Docker image in ACR - Which can be prepared using the container for interacting with AKS. More info about that in the 'Docker container for interacting with AKS' section in this document.
- values.yaml file - Which can be generated by the Terraform code. More info about that in the 'Files generated by Terraform (using template files)' section in this document.

## Service Principal for ACR Secret
When creating the secret from this chart (templates > common > acr-secret.yaml) we need to use for username and password Service Principal's credentials which has a scope for our ACR and role 'acrpush'. It is required for proper authentication.




# MLflow project Helm chart
In the docker > helm_charts > mlflow_project folder we have saved Helm chart used for running the MLflow project. It runs this project as a Job.

A few important aspects of how this work:
- **Service Account**
    - When deploying a Job running the MLflow project, it uses the Service Account created by the 'MLflow setup' Helm chart.
    - This Service Account is used by the Job to read the Secret which contains value for authentication when pulling image from ACR.
- **Docker image**
    - It pulls a Docker image from ACR prepared when starting the container for interacting with AKS (more info in the 'Docker container for interacting with AKS' section).
- **MLflow run command**
    - In the values.yaml file in this chart we specify a command to run the MLflow project.
- **Mounted project files**
    - MLflow project files which we will run are saved in File share in Azure Storage Account which is mounted to the Job running the project.

## Created Job and Pod names
When we install the chart for running MLflow project, it will create a Job and a Pod called '\<realese-name\>-\<chart-name\>-xxx', where:
- \<release-name\> is set up during installing the chart using command `helm install \<release-name\> \<project-path\> -n \<namespace\>`
- \<chart-name\> is set up in the Chart.yaml file

This way, if we use each time using a different release name, we can run multiple MLflow projects, every time creating a new Job. 

## values.yaml
The values.yaml file is generated by Terraform (more info in the 'Files generated by Terraform (using template files)' section).





# (Section to fix. Doesn't describe the latest changes.) MLflow project
Here is described how the MLflow project works.

The MLflow poject is saved in the docker > mlflow_project folder. Some of the files will be added to this folder by Terraform:
- backend_config.yaml
- MLproject
- mlflow-job-template.yaml

That's because some of the values in those files depends on resources created in Azure.

We will be running MLflow project from the localhost, outside of the container for interacting with AKS (created using the Dockerfile generated by Terraform).

We do this because running MLflow project requires to have installed Docker and installing and running Docker inside of a container is tricky.

How the MLflow project works:
- Use a Docker image we pushed to ACR (from the container for interacting with AKS)
- We have two enetrypoints in the MLproject file:
    - train:
        - Run the train.py script
        - Train a model on a fake data generated in this script
        - Save the trained model in the artifact store in a specified experiment
    - evaluate:
        - Run the evaluate.py script
        - Load the latest trained model from the artifact store for the same experiment used for training (that will be the model which we just trained in this project)
        - Evaluate the model
        - Log metrics in a new experiment (this experiment name will be the same as the one used for training but with the '_eval' suffix)
- We run MLflow project on AKS using the following files:
    - backend_config.json - Specifies how the project will be ran on Kubernetes
    - mlflow-job-template.yaml - A Kubernetes Job manifest which will be used to run MLflow project on Kubernetes
    - MLproject - Specifies what scripts to run and with which parameters

Instead of evaluating the latest trained model, we could save in a file a run ID of that trained model, read it in the script for evaluation and evaluate a model with this specific run ID.

## MLflow project files preparation
Those files from our MLflow project are being prepared by the Terraform code as their content is dependent on the created Azure resources:
- backend_config.json
- MLproject
- mlflow-job-template.yaml

Additionally, when we run a container for interacting with AKS using the Dockerfile generated by Terraform, 







# Docker container for interacting with AKS
Terraform code will generate a Dockerfile and save it in the docker folder in this repository. Docker image created by this Dockerfile is used to:
- Build and push to ACR Docker images
    - It is done when starting a container
    - Those images will be used by the MLflow Tracking Server and project
- Install Helm charts:
    - For deploying Tracking Server
    - For running MLflow project
- Interact with AKS using kubectl

In this image we are going to have:
- Installed Azure CLI - Which will be used to:
    - Get credentials to AKS (create the .kube/config file) what will enable using kubectl
    - Push images to ACR
- Installed and configured kubectl:
    - We will have prepared the .kube/config file used for authentication to AKS which enables us using kubectl.
- Installed Helm

## Build and push to ACR Docker images
When starting a container for interacting with AKS, the build_and_push.sh bash script will be executed which will build and push to ACR Docker images.

This script is using files from the docker > mlflow_docker folder (which is copied from the repo into the image). In this folder we have Dockerfiles for building images and other files used by those Dockerfiles.

## Service Principal for permissions
When building this Docker image we will run the following Azure CLI commands:
- `az aks get-credentials` - To create the kubeconfig file (.kube/config). That will allow us to use kubectl to interact with our AKS cluster.
- `az acr build` - To build and push to ACR Docker images.

Running those commands requires proper permissions. That's why, when building this image, we need to login to Azure using `az login` using a Service Principal with proper roles and scopes:
- Role 'Contributor' with scope for ACR - Enable pushing images to ACR using the `az acr build` command
- Role 'Azure Kubernetes Service Cluster User Role' with scope for AKS - Enable getting credentials to AKS (creating .kube/config file) using the `az aks get-credentials` command






# Creating Azure resources with Terraform
This section explains what Azure resources and files we create using Terraform and how.

We have there the main.tf file which creates all the resources. That file uses modules defined in the terraform_linux_vm > modules folder. Each module is dedicated to creating one type of resource in Azure.

## Resources created
Resources which we create are:
- Two resource groups
- Log Analytics workspace - For AKS monitoring.
- AKS
- ACR - For storing Docker images used when deploying resources on AKS.
- Service Principal - With proper scopes and roles which will be used in the Dockerfile generated by Terraform for authentication when interacting with AKS and ACR. More details about assigned roles and scopes can be found in comments in the main.tf file when creating this Service Principal.
- Storage Account with:
    - Container - Which will act as an artifact store for MLflow Tracking Server.
    - File share - Where we will store MLflow project files and which will be mounted into the Job running MLflow project

## Files generated by Terraform (using template files)
Additionally Terraform saves files on the localhost where we run Terraform code:
- Dockerfile:
    - Used to run a container with prepared environment to interact with AKS
    - Saved in the docker folder
- values.yaml x2:
    - Two values.yaml files used in Helm charts:
    - Saved in the mlflow_project and mlflow_setup folders in the docker > helm_charts folder.

In the template_files folder we have templates of those files. We will interpolate them (insert variables values) and save on the localhost.

## Terraform outputs
Terraform creates multiple outputs with information about created resources. They are not needed to use code from this repo but might be useful in some situations. They can be accessed by running the command:
>terraform output

## Kubeconfig file
It is possible to use Terraform to save on our local machine a kubeconfig file when creating AKS but we don't do this since we generate a kubeconfig file in a Docker image using Azure CLI.





# AKS resources deployment - details
Here is more details about resources we are deploying on AKS.

## MySQL volume
When creating a volume for MySQL resource we specify `storageClassName: managed-csi` which indicates that we want to use an Azure Disk for storage (this disk gets created when we create a volume).

When we delete that volume then Azure Disk gets deleted as well.